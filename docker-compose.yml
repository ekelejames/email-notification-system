services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: notification_db
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: notificationdb
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - notification_network

  mongo:
    image: mongo
    container_name: mongo
    ports:
      - "27017:27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=root
      - MONGO_INITDB_ROOT_PASSWORD=root
    volumes:
      - ./mongo-data:/data/db
    networks:
      - notification_network



  mongo-express:
    image: mongo-express
    container_name: mongo-express
    ports:
      - "8084:8081" # Mapping host port 8084 to container port 8081
    environment:
      - ME_CONFIG_MONGODB_ADMINUSERNAME=root
      - ME_CONFIG_MONGODB_ADMINPASSWORD=root
      - ME_CONFIG_MONGODB_SERVER=mongo
      - ME_CONFIG_BASICAUTH_USERNAME=admin
      - ME_CONFIG_BASICAUTH_PASSWORD=admin_pass
    depends_on:
      - kafka
    networks:
      - notification_network


  # Redis for caching and rate limiting
  redis:
    image: redis:7-alpine
    container_name: redis_cache
    ports:
      - "6379:6379"
    volumes:
      - ./redis_data:/data
    networks:
      - notification_network
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    environment:
      CLUSTER_ID: 'xVwOh_nFSfq2tXYyxPXDTQ'
      KAFKA_BROKER_ID: 2
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '2@0.0.0.0:29093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,INTERNAL:SASL_PLAINTEXT,EXTERNAL:PLAINTEXT,CLIENT:PLAINTEXT
      KAFKA_LISTENERS: 'INTERNAL://0.0.0.0:9092,EXTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,CLIENT://0.0.0.0:29094'
      KAFKA_ADVERTISED_LISTENERS: 'INTERNAL://kafka:9092,CLIENT://localhost:29094,EXTERNAL://kafka:29092'
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_LOG_DIRS: '/var/lib/kafka/data-2'
      KAFKA_AUTHORIZER_CLASS_NAME: io.confluent.kafka.security.authorizer.ConfluentServerAuthorizer
      KAFKA_CONFLUENT_AUDIT_LOG_ENABLED: true
      KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "false"
      KAFKA_SUPER_USERS: "User:admin;User:ANONYMOUS"
      KAFKA_SASL_ENABLED_MECHANISMS: PLAIN
      KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: PLAIN
      KAFKA_OPTS: "-Djava.security.auth.login.config=/etc/kafka/jaas.conf"
      # connecting to external listener
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:9092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
      CONFLUENT_METRICS_REPORTER_SASL_MECHANISM: PLAIN
      CONFLUENT_METRICS_REPORTER_SECURITY_PROTOCOL: SASL_PLAINTEXT
      CONFLUENT_METRICS_REPORTER_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";'
      # Configuring debugging level
      KAFKA_LOG4J_ROOT_LOGLEVEL: 'INFO'
      KAFKA_LOG4J_LOGGERS: 'kafka=INFO,kafka.controller=INFO,kafka.log.LogCleaner=INFO,state.change.logger=INFO,kafka.producer.async.DefaultEventHandler=INFO'
      KAFKA_SASL_KERBEROS_SERVICE_NAME: kafka
    volumes:
      - ./jaas.conf:/etc/kafka/jaas.conf
    image: confluentinc/cp-server:7.6.0
    container_name: kafka
    ports:
      - "29092:29092"
      - "9092:9092"
      - "29094:29094"
    networks:
      - notification_network
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:29092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 40s



  control-center:
    image: confluentinc/cp-enterprise-control-center:7.6.0
    container_name: control-center
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka:29092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_LOG4J_ROOT_LOGLEVEL: 'INFO'
    depends_on:
      - kafka
    networks:
      - notification_network


  kafka-connect:
    build:
      context: .
      dockerfile: Dockerfile.kafka-connect
    container_name: kafka-connect
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'kafka-connect'
      CONNECT_GROUP_ID: 'kafka-connect-group'
      CONNECT_CONFIG_STORAGE_TOPIC: 'connect-configs'
      CONNECT_OFFSET_STORAGE_TOPIC: 'connect-offsets'
      CONNECT_STATUS_STORAGE_TOPIC: 'connect-status'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_VALUE_CONVERTER: 'io.confluent.connect.json.JsonSchemaConverter'
      CONNECT_REST_PORT: 8083
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components,/kafka-plugins'
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CONNECT_SECURITY_PROTOCOL: PLAINTEXT
      CONNECT_PRODUCER_SECURITY_PROTOCOL: PLAINTEXT
      CONNECT_CONSUMER_SECURITY_PROTOCOL: PLAINTEXT
    volumes:
      - ./plugins/kafka-plugins:/kafka-plugins
      - ./mongodb-kafka-connect-mongodb-1.14.1:/usr/share/confluent-hub-components
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8083/"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - notification_network

  # Log UI Service (with MongoDB)
  logui:
    build:
      context: ./logUI
      dockerfile: Dockerfile
    container_name: log_ui
    environment:
      MONGO_URL: mongodb://root:root@mongo:27017
      MONGO_AUTH_SOURCE: admin
    ports:
      - "8442:8442"
    networks:
      - notification_network
    restart: unless-stopped
    depends_on:
      - mongo


  # Producer Service (with Redis caching)
  producer:
    build:
      context: ./producer
      dockerfile: Dockerfile
    container_name: producer_service
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      logui:
        condition: service_started
    environment:
      DATABASE_URL: postgresql://admin:admin@postgres:5432/notificationdb
      KAFKA_BROKER: kafka:29092
      REDIS_URL: redis://redis:6379
      LOG_SERVER: http://logui:8442
      NODE_ENV: production
    ports:
      - "3001:3001"
    networks:
      - notification_network
    restart: unless-stopped

  # Consumer Service
  consumer:
    build:
      context: ./consumer
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
      logui:
        condition: service_started
    environment:
      DATABASE_URL: postgresql://admin:admin@postgres:5432/notificationdb
      KAFKA_BROKER: kafka:29092
      SMTP_HOST: ${SMTP_HOST:-smtp.gmail.com}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USER: ${SMTP_USER:-your-email@gmail.com}
      SMTP_PASS: ${SMTP_PASS:-your-password}
      LOG_SERVER: http://logui:8442
      NODE_ENV: production
    networks:
      - notification_network
      - default
    restart: unless-stopped


  # Frontend Template Editor
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: template_editor_ui
    depends_on:
      - producer
    environment:
      API_URL: http://producer:3001
    ports:
      - "3000:80"
    networks:
      - notification_network

volumes:
  postgres_data:
  mongo_data:
  redis_data:
  kafka_data:

networks:
  notification_network:
    driver: bridge
